{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task 1: Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "from datasets import load_dataset\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt \n",
        "import seaborn as sns\n",
        "from transformers import ViTImageProcessor, ViTForImageClassification, TrainingArguments, Trainer\n",
        "from torchvision import transforms\n",
        "import sklearn\n",
        "import numpy as np \n",
        "import torch\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task 2: Load the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# download the dataset\n",
        "load_dataset('mnist',cache_dir='mnist_dataset')\n",
        "\n",
        "path = 'mnist_dataset/'\n",
        "train_validation_ds = load_dataset(path=path,split='train[:1000]')\n",
        "test_ds = load_dataset(path=path,split='test[:100]')\n",
        "\n",
        "splits = train_validation_ds.train_test_split(test_size=0.1)\n",
        "train_ds = splits['train']\n",
        "validation_ds = splits['test']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task 3: Visualize the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_ds['image'][449]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_labels = Counter(train_ds['label'])\n",
        "plt.clf()\n",
        "plt.bar(train_labels.keys(),train_labels.values())\n",
        "plt.title('Training dataset')\n",
        "plt.xlabel('Label')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "val_labels = Counter(validation_ds['label'])\n",
        "plt.clf()\n",
        "plt.bar(val_labels.keys(),val_labels.values())\n",
        "plt.title('Validation dataset')\n",
        "plt.xlabel('Label')\n",
        "plt.ylabel('Frequency')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task 4: Create a Mapping of Class Names to Index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "id2label = {id : label for id,label in enumerate(train_ds.features['label'].names)}\n",
        "label2id = {t[1] : t[0] for t in id2label.items()}\n",
        "num_labels = len(id2label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task 5: Load the Preprocessor for the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "PRETRAINED_MODEL_NAME = 'google/vit-base-patch16-224'\n",
        "processor = ViTImageProcessor.from_pretrained(PRETRAINED_MODEL_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task 6: Define Data Augmentations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image_mean, image_std = processor.image_mean, processor.image_std\n",
        "height, width = processor.size['height'], processor.size['width']\n",
        "\n",
        "normalize = transforms.Normalize(mean=image_mean,std=image_std)\n",
        "\n",
        "_train_transforms = transforms.Compose([\n",
        "                                    # transforms.RandomAffine(degrees=10,translate=(0.1,0.1),scale=(0.9,1.1)),\n",
        "                                    transforms.Resize((height,width)),\n",
        "                                    transforms.ToTensor(),\n",
        "                                    normalize])\n",
        "\n",
        "_validation_transforms = transforms.Compose([\n",
        "                                    transforms.Resize((height,width)),\n",
        "                                    transforms.ToTensor(),\n",
        "                                    normalize])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task 7:  Implement Data Transformation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_transforms(batch):\n",
        "    rgb_images = [img.convert('RGB') for img in batch['image']]\n",
        "    batch['pixel_values'] = [_train_transforms(img) for img in rgb_images]\n",
        "    return batch\n",
        "\n",
        "def validation_transforms(batch):\n",
        "    rgb_images = [img.convert('RGB') for img in batch['image']]\n",
        "    batch['pixel_values'] = [_validation_transforms(img) for img in rgb_images]\n",
        "    return batch\n",
        "\n",
        "train_ds.set_transform(train_transforms)\n",
        "validation_ds.set_transform(validation_transforms)\n",
        "test_ds.set_transform(validation_transforms)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task 8: Collate the Function for DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def collate_fn(batch):\n",
        "    pixel_values = torch.stack([sample['pixel_values'] for sample in batch])\n",
        "    labels = torch.tensor([sample['label'] for sample in batch])\n",
        "    return {'pixel_values' : pixel_values, 'labels' : labels}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task 9: Create a Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = ViTForImageClassification.from_pretrained(pretrained_model_name_or_path=PRETRAINED_MODEL_NAME, \n",
        "                                                num_labels = num_labels,\n",
        "                                                id2label = id2label,\n",
        "                                                label2id = label2id,\n",
        "                                                ignore_mismatched_sizes=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task 10: Define a Metric for the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    f1 = sklearn.metrics.f1_score(labels, predictions, average='macro') # just average the metrics\n",
        "    return {'f1' : f1}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task 11: Set Up Trainer Arguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output_dir ='./trained_model'\n",
        "# create unique directory name for tensorboard logs\n",
        "tensorboard_dir = f'./logs/{datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")}'\n",
        "training_args = TrainingArguments(output_dir=output_dir,\n",
        "                                                 num_train_epochs=20,\n",
        "                                                 learning_rate=0.00001,\n",
        "                                                 per_device_train_batch_size=16,\n",
        "                                                 per_device_eval_batch_size=64,\n",
        "                                                 logging_dir=tensorboard_dir,\n",
        "                                                 logging_strategy='epoch',\n",
        "                                                 evaluation_strategy='epoch',\n",
        "                                                 remove_unused_columns=False,\n",
        "                                                 load_best_model_at_end=True,\n",
        "                                                 save_strategy='epoch',\n",
        "                                                 metric_for_best_model=\"eval_loss\",\n",
        "                                                greater_is_better=False,\n",
        "                                                warmup_ratio=0.1\n",
        "                                                 )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task 12: Create a Trainer Object"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MNISTTrainer(Trainer):\n",
        "    # write a custom collate function\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.data_collator = collate_fn\n",
        "\n",
        "trainer = MNISTTrainer(model=model,\n",
        "                  args=training_args,\n",
        "                  compute_metrics=compute_metrics,\n",
        "                  train_dataset=train_ds,\n",
        "                  eval_dataset=validation_ds,\n",
        "                  )   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task 13: Evaluate the Model Before Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer.evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task 14: Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # freeze all the layers except the last layer\n",
        "# for name, param in model.named_parameters():\n",
        "#     if 'classifier' not in name:\n",
        "#         param.requires_grad = False\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task 15: Visualize the Performance in TensorBoard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# visualize the training loss, learning rate and f1 score using tensorboard in vscode\n",
        "%load_ext tensorboard\n",
        "#!tensorboard --logdir './logs'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task 16: Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# clear the cache in ./trained_model\n",
        "!rm -r ./trained_model/*\n",
        "trainer.evaluate(validation_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task 17: Set Up the Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task 18: Save the Model and Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task 19: Set Up an Inference for the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
